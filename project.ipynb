{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1\n",
      "CUDA available: True\n",
      "CUDA device: NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA is available and set the default tensor type to use CUDA if available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.read_csv('data/news.csv')\n",
    "stock_df = pd.read_csv('data/price.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>A</td>\n",
       "      <td>43.743862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>A</td>\n",
       "      <td>44.317825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>A</td>\n",
       "      <td>43.790924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>A</td>\n",
       "      <td>45.155281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>A</td>\n",
       "      <td>45.296406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date ticker      close\n",
       "0  2017-01-03      A  43.743862\n",
       "1  2017-01-04      A  44.317825\n",
       "2  2017-01-05      A  43.790924\n",
       "3  2017-01-06      A  45.155281\n",
       "4  2017-01-09      A  45.296406"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\drebi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"vader_lexicon\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "finbert_tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')\n",
    "finbert = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone')\n",
    "\n",
    "# nlp = pipeline(\"sentiment-analysis\", model=finbert, tokenizer=tokenizer, max_length=512, truncation=True)\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    inputs = finbert_tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = finbert(**inputs)\n",
    "    scores = outputs.logits.softmax(dim=1).numpy()[0]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of scores into a DataFrame with separate columns\n",
    "sentiment_df = pd.DataFrame(news_df['body'].apply(predict_sentiment).tolist(), columns=['neutral', 'positive', 'negative'])\n",
    "\n",
    "# Append the new columns to news_df\n",
    "news_df = pd.concat([news_df.reset_index(drop=True), sentiment_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VADER_sentiment_score(heading):\n",
    "    \"\"\"\n",
    "    Returns all VADER sentiment scores\n",
    "    - neg: Negative sentiment (0 to 1)\n",
    "    - neu: Neutral sentiment (0 to 1)\n",
    "    - pos: Positive sentiment (0 to 1)\n",
    "    compound: Normalized aggregate score (-1 to 1)\n",
    "    \"\"\"\n",
    "\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    return analyzer.polarity_scores(heading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 items\n",
      "Processed 100 items\n",
      "Processed 200 items\n",
      "Processed 300 items\n",
      "Processed 400 items\n",
      "Processed 500 items\n",
      "Processed 600 items\n",
      "Processed 700 items\n",
      "Processed 800 items\n",
      "Processed 900 items\n",
      "Processed 1000 items\n",
      "Processed 1100 items\n",
      "Processed 1200 items\n",
      "Processed 1300 items\n",
      "Processed 1400 items\n",
      "Processed 1500 items\n",
      "Processed 1600 items\n",
      "Processed 1700 items\n",
      "Processed 1800 items\n",
      "Processed 1900 items\n",
      "Processed 2000 items\n",
      "Processed 2100 items\n",
      "Processed 2200 items\n",
      "Processed 2300 items\n",
      "Processed 2400 items\n",
      "Processed 2500 items\n",
      "Processed 2600 items\n",
      "Processed 2700 items\n",
      "Processed 2800 items\n",
      "Processed 2900 items\n",
      "Processed 3000 items\n",
      "Processed 3100 items\n",
      "Processed 3200 items\n",
      "Processed 3300 items\n",
      "Processed 3400 items\n",
      "Processed 3500 items\n",
      "Processed 3600 items\n",
      "Processed 3700 items\n",
      "Processed 3800 items\n",
      "Processed 3900 items\n",
      "Processed 4000 items\n",
      "Processed 4100 items\n",
      "Processed 4200 items\n",
      "Processed 4300 items\n",
      "Processed 4400 items\n",
      "Processed 4500 items\n",
      "Processed 4600 items\n",
      "Processed 4700 items\n",
      "Processed 4800 items\n",
      "Processed 4900 items\n",
      "Processed 5000 items\n",
      "Processed 5100 items\n",
      "Processed 5200 items\n",
      "Processed 5300 items\n",
      "Processed 5400 items\n",
      "Processed 5500 items\n",
      "Processed 5600 items\n",
      "Processed 5700 items\n",
      "Processed 5800 items\n",
      "Processed 5900 items\n",
      "Processed 6000 items\n",
      "Processed 6100 items\n",
      "Processed 6200 items\n",
      "Processed 6300 items\n",
      "Processed 6400 items\n",
      "Processed 6500 items\n",
      "Processed 6600 items\n",
      "Processed 6700 items\n",
      "Processed 6800 items\n",
      "Processed 6900 items\n",
      "Processed 7000 items\n",
      "Processed 7100 items\n",
      "Processed 7200 items\n",
      "Processed 7300 items\n",
      "Processed 7400 items\n",
      "Processed 7500 items\n",
      "Processed 7600 items\n",
      "Processed 7700 items\n",
      "Processed 7800 items\n",
      "Processed 7900 items\n",
      "Processed 8000 items\n",
      "Processed 8100 items\n",
      "Processed 8200 items\n",
      "Processed 8300 items\n",
      "Processed 8400 items\n",
      "Processed 8500 items\n",
      "Processed 8600 items\n",
      "Processed 8700 items\n",
      "Processed 8800 items\n",
      "Processed 8900 items\n",
      "Processed 9000 items\n",
      "Processed 9100 items\n",
      "Processed 9200 items\n",
      "Processed 9300 items\n",
      "Processed 9400 items\n",
      "Processed 9500 items\n",
      "Processed 9600 items\n",
      "Processed 9700 items\n",
      "Processed 9800 items\n",
      "Processed 9900 items\n",
      "Processed 10000 items\n",
      "Processed 10100 items\n",
      "Processed 10200 items\n",
      "Processed 10300 items\n",
      "Processed 10400 items\n",
      "Processed 10500 items\n",
      "Processed 10600 items\n",
      "Processed 10700 items\n",
      "Processed 10800 items\n",
      "Processed 10900 items\n",
      "Processed 11000 items\n",
      "Processed 11100 items\n",
      "Processed 11200 items\n",
      "Processed 11300 items\n",
      "Processed 11400 items\n",
      "Processed 11500 items\n",
      "Processed 11600 items\n",
      "Processed 11700 items\n",
      "Processed 11800 items\n",
      "Processed 11900 items\n",
      "Processed 12000 items\n",
      "Processed 12100 items\n",
      "Processed 12200 items\n",
      "Processed 12300 items\n",
      "Processed 12400 items\n",
      "Processed 12500 items\n",
      "Processed 12600 items\n",
      "Processed 12700 items\n",
      "Processed 12800 items\n",
      "Processed 12900 items\n",
      "Processed 13000 items\n",
      "Processed 13100 items\n",
      "Processed 13200 items\n",
      "Processed 13300 items\n",
      "Processed 13400 items\n",
      "Processed 13500 items\n",
      "Processed 13600 items\n",
      "Processed 13700 items\n",
      "Processed 13800 items\n",
      "Processed 13900 items\n",
      "Processed 14000 items\n",
      "Processed 14100 items\n",
      "Processed 14200 items\n",
      "Processed 14300 items\n",
      "Processed 14400 items\n",
      "Processed 14500 items\n",
      "Processed 14600 items\n",
      "Processed 14700 items\n",
      "Processed 14800 items\n",
      "Processed 14900 items\n",
      "Processed 15000 items\n",
      "Processed 15100 items\n",
      "Processed 15200 items\n",
      "Processed 15300 items\n",
      "Processed 15400 items\n",
      "Processed 15500 items\n",
      "Processed 15600 items\n",
      "Processed 15700 items\n",
      "Processed 15800 items\n",
      "Processed 15900 items\n",
      "Processed 16000 items\n",
      "Processed 16100 items\n",
      "Processed 16200 items\n",
      "Processed 16300 items\n",
      "Processed 16400 items\n",
      "Processed 16500 items\n",
      "Processed 16600 items\n",
      "Processed 16700 items\n",
      "Processed 16800 items\n",
      "Processed 16900 items\n",
      "Processed 17000 items\n",
      "Processed 17100 items\n",
      "Processed 17200 items\n",
      "Processed 17300 items\n",
      "Processed 17400 items\n",
      "Processed 17500 items\n",
      "Processed 17600 items\n",
      "Processed 17700 items\n",
      "Processed 17800 items\n",
      "Processed 17900 items\n",
      "Processed 18000 items\n",
      "Processed 18100 items\n",
      "Processed 18200 items\n",
      "Processed 18300 items\n",
      "Processed 18400 items\n",
      "Processed 18500 items\n",
      "Processed 18600 items\n",
      "Processed 18700 items\n",
      "Processed 18800 items\n",
      "Processed 18900 items\n",
      "Processed 19000 items\n",
      "Processed 19100 items\n",
      "Processed 19200 items\n",
      "Processed 19300 items\n",
      "Processed 19400 items\n",
      "Processed 19500 items\n",
      "Processed 19600 items\n",
      "Processed 19700 items\n",
      "Processed 19800 items\n",
      "Processed 19900 items\n",
      "Processed 20000 items\n",
      "Processed 20100 items\n",
      "Processed 20200 items\n",
      "Processed 20300 items\n",
      "Processed 20400 items\n",
      "Processed 20500 items\n"
     ]
    }
   ],
   "source": [
    "VADER_negative = []\n",
    "VADER_neutral = []\n",
    "VADER_positive = []\n",
    "VADER_compound = []\n",
    "\n",
    "\n",
    "for i in range(len(news_df)):\n",
    "    \n",
    "    headline = news_df.iloc[i]['title']\n",
    "\n",
    "    # Analyze headline with VADER\n",
    "    vader_scores = VADER_sentiment_score(headline)\n",
    "    VADER_negative.append(vader_scores['neg'])\n",
    "    VADER_neutral.append(vader_scores['neu'])\n",
    "    VADER_positive.append(vader_scores['pos'])\n",
    "    VADER_compound.append(vader_scores['compound'])\n",
    "\n",
    "\n",
    "    # Optional: Print progress every 100 items\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Processed {i} items\")\n",
    "\n",
    "\n",
    "    # Get all sentiment scores\n",
    "\n",
    "# Add all scores to the dataframe\n",
    "news_df['VADER_negative'] = VADER_negative\n",
    "news_df['VADER_neutral'] = VADER_neutral\n",
    "news_df['VADER_positive'] = VADER_positive\n",
    "news_df['VADER_compound'] = VADER_compound\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publication_datetime</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>tickers</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>VADER_negative</th>\n",
       "      <th>VADER_neutral</th>\n",
       "      <th>VADER_positive</th>\n",
       "      <th>VADER_compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>World News: Police Question Netanyahu Over Gifts</td>\n",
       "      <td>\"We pay attention to publications in the media...</td>\n",
       "      <td>EL</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>Business News: Nestle Turns to New CEO for Hea...</td>\n",
       "      <td>Nestle, the world's largest packaged-food comp...</td>\n",
       "      <td>GIS</td>\n",
       "      <td>0.444897</td>\n",
       "      <td>0.551795</td>\n",
       "      <td>0.003308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>Business News: Vermont Drug Law Faces Limits -...</td>\n",
       "      <td>The Vermont law, enacted in June, instructed s...</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>0.999891</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>Life &amp; Arts -- Travel: How Hotel Companies Lau...</td>\n",
       "      <td>Travelers are about to see a flurry of new hot...</td>\n",
       "      <td>HLT</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>Businesses Ready to Ramp Up Investment --- Aft...</td>\n",
       "      <td>The Federal Reserve last month signaled intere...</td>\n",
       "      <td>HD</td>\n",
       "      <td>0.984549</td>\n",
       "      <td>0.013953</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.3612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  publication_datetime                                              title  \\\n",
       "0           2017-01-03   World News: Police Question Netanyahu Over Gifts   \n",
       "1           2017-01-03  Business News: Nestle Turns to New CEO for Hea...   \n",
       "2           2017-01-03  Business News: Vermont Drug Law Faces Limits -...   \n",
       "3           2017-01-03  Life & Arts -- Travel: How Hotel Companies Lau...   \n",
       "4           2017-01-03  Businesses Ready to Ramp Up Investment --- Aft...   \n",
       "\n",
       "                                                body tickers   neutral  \\\n",
       "0  \"We pay attention to publications in the media...      EL  0.999937   \n",
       "1  Nestle, the world's largest packaged-food comp...     GIS  0.444897   \n",
       "2  The Vermont law, enacted in June, instructed s...    ABBV  0.999891   \n",
       "3  Travelers are about to see a flurry of new hot...     HLT  0.999991   \n",
       "4  The Federal Reserve last month signaled intere...      HD  0.984549   \n",
       "\n",
       "   positive  negative  VADER_negative  VADER_neutral  VADER_positive  \\\n",
       "0  0.000002  0.000060             0.0          1.000           0.000   \n",
       "1  0.551795  0.003308             0.0          1.000           0.000   \n",
       "2  0.000026  0.000083             0.0          1.000           0.000   \n",
       "3  0.000006  0.000003             0.0          1.000           0.000   \n",
       "4  0.013953  0.001498             0.0          0.894           0.106   \n",
       "\n",
       "   VADER_compound  \n",
       "0          0.0000  \n",
       "1          0.0000  \n",
       "2          0.0000  \n",
       "3          0.0000  \n",
       "4          0.3612  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.to_csv('data/news_w_sentiment.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publication_datetime</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>tickers</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>VADER_negative</th>\n",
       "      <th>VADER_neutral</th>\n",
       "      <th>VADER_positive</th>\n",
       "      <th>VADER_compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>World News: Police Question Netanyahu Over Gifts</td>\n",
       "      <td>\"We pay attention to publications in the media...</td>\n",
       "      <td>EL</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>Business News: Nestle Turns to New CEO for Hea...</td>\n",
       "      <td>Nestle, the world's largest packaged-food comp...</td>\n",
       "      <td>GIS</td>\n",
       "      <td>0.444897</td>\n",
       "      <td>0.551795</td>\n",
       "      <td>0.003308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>Business News: Vermont Drug Law Faces Limits -...</td>\n",
       "      <td>The Vermont law, enacted in June, instructed s...</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>0.999891</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>Life &amp; Arts -- Travel: How Hotel Companies Lau...</td>\n",
       "      <td>Travelers are about to see a flurry of new hot...</td>\n",
       "      <td>HLT</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>Businesses Ready to Ramp Up Investment --- Aft...</td>\n",
       "      <td>The Federal Reserve last month signaled intere...</td>\n",
       "      <td>HD</td>\n",
       "      <td>0.984549</td>\n",
       "      <td>0.013953</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.3612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  publication_datetime                                              title  \\\n",
       "0           2017-01-03   World News: Police Question Netanyahu Over Gifts   \n",
       "1           2017-01-03  Business News: Nestle Turns to New CEO for Hea...   \n",
       "2           2017-01-03  Business News: Vermont Drug Law Faces Limits -...   \n",
       "3           2017-01-03  Life & Arts -- Travel: How Hotel Companies Lau...   \n",
       "4           2017-01-03  Businesses Ready to Ramp Up Investment --- Aft...   \n",
       "\n",
       "                                                body tickers   neutral  \\\n",
       "0  \"We pay attention to publications in the media...      EL  0.999937   \n",
       "1  Nestle, the world's largest packaged-food comp...     GIS  0.444897   \n",
       "2  The Vermont law, enacted in June, instructed s...    ABBV  0.999891   \n",
       "3  Travelers are about to see a flurry of new hot...     HLT  0.999991   \n",
       "4  The Federal Reserve last month signaled intere...      HD  0.984549   \n",
       "\n",
       "   positive  negative  VADER_negative  VADER_neutral  VADER_positive  \\\n",
       "0  0.000002  0.000060             0.0          1.000           0.000   \n",
       "1  0.551795  0.003308             0.0          1.000           0.000   \n",
       "2  0.000026  0.000083             0.0          1.000           0.000   \n",
       "3  0.000006  0.000003             0.0          1.000           0.000   \n",
       "4  0.013953  0.001498             0.0          0.894           0.106   \n",
       "\n",
       "   VADER_compound  \n",
       "0          0.0000  \n",
       "1          0.0000  \n",
       "2          0.0000  \n",
       "3          0.0000  \n",
       "4          0.3612  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df = pd.read_csv('data/news_w_sentiment.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "split = (0.75);\n",
    "sequence_length = 10;\n",
    "epochs = 100\n",
    "learning_rate = 0.02\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading stock price data\n",
    "stock_data = pd.read_csv(\"stock_price.csv\")\n",
    "column = ['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_stock_data = stock_data.shape[0]\n",
    "\n",
    "\n",
    "# splitting data to train and test\n",
    "train_examples = int(len_stock_data * split)\n",
    "train = stock_data.get(column).values[:train_examples]\n",
    "test = stock_data.get(column).values[train_examples:]\n",
    "len_train = train.shape[0]\n",
    "len_test = test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "train, test = scaler.fit_transform(train), scaler.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting training data to x and y\n",
    "X_train = []\n",
    "for i in range(len_train - sequence_length):\n",
    "    X_train.append(train[i : i + sequence_length])\n",
    "X_train = np.array(X_train).astype(float)\n",
    "y_train = np.array(train[sequence_length:]).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting testing data to x and y\n",
    "X_test = []\n",
    "for i in range(len_test - sequence_length):\n",
    "    X_test.append(test[i : i + sequence_length])\n",
    "X_test = np.array(X_test).astype(float)\n",
    "y_test = np.array(test[sequence_length:]).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating LSTM model\n",
    "def model_create():\n",
    "    tf.random.set_seed(1234)\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            tf.keras.Input(shape=(X_train.shape[1], 1)),\n",
    "            tf.keras.layers.LSTM(units=50, activation=\"tanh\", return_sequences=True),\n",
    "            tf.keras.layers.Dropout(0.15),\n",
    "            tf.keras.layers.LSTM(units=30, activation=\"tanh\", return_sequences=True),\n",
    "            tf.keras.layers.Dropout(0.05),\n",
    "            tf.keras.layers.LSTM(units=20, activation=\"tanh\", return_sequences=False),\n",
    "            tf.keras.layers.Dropout(0.01),\n",
    "            tf.keras.layers.Dense(units=1, activation=\"linear\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "    )\n",
    "\n",
    "    # Fit the model and store the history\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        validation_split=0.2,\n",
    "        verbose=1\n",
    "    )\n",
    "    return model, history\n",
    "\n",
    "\n",
    "# inverting normaliztion\n",
    "y_test = scaler.inverse_transform(y_test)\n",
    "\n",
    "\n",
    "# prediction on test set\n",
    "def predict(model):\n",
    "    predictions = model.predict(X_test)\n",
    "    predictions = scaler.inverse_transform(predictions.reshape(-1, 1)).reshape(-1, 1)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# evaluation\n",
    "def evaluate(predictions):\n",
    "    mae = mean_absolute_error(predictions, y_test)\n",
    "    mape = mean_absolute_percentage_error(predictions, y_test)\n",
    "    return mae, mape, (1 - mape)\n",
    "\n",
    "\n",
    "def run_model(n):\n",
    "\n",
    "    total_mae = total_mape = total_acc = 0\n",
    "    histories = []\n",
    "\n",
    "    for i in range(n):\n",
    "        model, history = model_create()\n",
    "        predictions = predict(model)\n",
    "        mae, mape, acc = evaluate(predictions)\n",
    "        total_mae += mae\n",
    "        total_mape += mape\n",
    "        total_acc += acc\n",
    "        histories.append(history)\n",
    "\n",
    "    return (total_mae / n), (total_mape / n), (total_acc / n), predictions.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - loss: 0.1712 - val_loss: 0.0432\n",
      "Epoch 2/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0504 - val_loss: 0.0672\n",
      "Epoch 3/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0344 - val_loss: 0.0169\n",
      "Epoch 4/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0162 - val_loss: 0.0101\n",
      "Epoch 5/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0076 - val_loss: 0.0154\n",
      "Epoch 6/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0050 - val_loss: 0.0107\n",
      "Epoch 7/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0039 - val_loss: 0.0117\n",
      "Epoch 8/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0044 - val_loss: 0.0105\n",
      "Epoch 9/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0039 - val_loss: 0.0110\n",
      "Epoch 10/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0033 - val_loss: 0.0110\n",
      "Epoch 11/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0035 - val_loss: 0.0110\n",
      "Epoch 12/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0030 - val_loss: 0.0106\n",
      "Epoch 13/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0027 - val_loss: 0.0115\n",
      "Epoch 14/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0031 - val_loss: 0.0110\n",
      "Epoch 15/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0030 - val_loss: 0.0103\n",
      "Epoch 16/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0029 - val_loss: 0.0102\n",
      "Epoch 17/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0032 - val_loss: 0.0125\n",
      "Epoch 18/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0035 - val_loss: 0.0103\n",
      "Epoch 19/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0031 - val_loss: 0.0095\n",
      "Epoch 20/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0026 - val_loss: 0.0104\n",
      "Epoch 21/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0029 - val_loss: 0.0105\n",
      "Epoch 22/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0030 - val_loss: 0.0085\n",
      "Epoch 23/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0027 - val_loss: 0.0091\n",
      "Epoch 24/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0028 - val_loss: 0.0095\n",
      "Epoch 25/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0027 - val_loss: 0.0081\n",
      "Epoch 26/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0027 - val_loss: 0.0086\n",
      "Epoch 27/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0026 - val_loss: 0.0091\n",
      "Epoch 28/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0029 - val_loss: 0.0075\n",
      "Epoch 29/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0023 - val_loss: 0.0081\n",
      "Epoch 30/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0026 - val_loss: 0.0068\n",
      "Epoch 31/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0023 - val_loss: 0.0066\n",
      "Epoch 32/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0020 - val_loss: 0.0077\n",
      "Epoch 33/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0023 - val_loss: 0.0062\n",
      "Epoch 34/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0023 - val_loss: 0.0063\n",
      "Epoch 35/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0024 - val_loss: 0.0071\n",
      "Epoch 36/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0025 - val_loss: 0.0057\n",
      "Epoch 37/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0023 - val_loss: 0.0065\n",
      "Epoch 38/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0021 - val_loss: 0.0056\n",
      "Epoch 39/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0019 - val_loss: 0.0078\n",
      "Epoch 40/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0025 - val_loss: 0.0054\n",
      "Epoch 41/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0020 - val_loss: 0.0050\n",
      "Epoch 42/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0023 - val_loss: 0.0069\n",
      "Epoch 43/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 44/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0025 - val_loss: 0.0060\n",
      "Epoch 45/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0023 - val_loss: 0.0062\n",
      "Epoch 46/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 47/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0016 - val_loss: 0.0060\n",
      "Epoch 48/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 49/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0022 - val_loss: 0.0051\n",
      "Epoch 50/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 51/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 52/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 53/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 54/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 55/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 56/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 57/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 58/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 59/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0016 - val_loss: 0.0056\n",
      "Epoch 60/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 61/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 62/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 63/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 64/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 65/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 66/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 67/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 68/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 69/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 70/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 71/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 72/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0013 - val_loss: 0.0034\n",
      "Epoch 73/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 74/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0013 - val_loss: 0.0034\n",
      "Epoch 75/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 76/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0013 - val_loss: 0.0034\n",
      "Epoch 77/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 78/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0013 - val_loss: 0.0032\n",
      "Epoch 79/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 80/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 81/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0013 - val_loss: 0.0032\n",
      "Epoch 82/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0012 - val_loss: 0.0030\n",
      "Epoch 83/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 84/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 85/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 86/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 87/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 88/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 89/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 90/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 91/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 92/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 93/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 94/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 95/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 96/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 97/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 98/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 99/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0012 - val_loss: 0.0027\n",
      "Epoch 100/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0012 - val_loss: 0.0028\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 5, got 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m mae, mape, acc, preds, histories = run_model(\u001b[32m1\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: not enough values to unpack (expected 5, got 4)"
     ]
    }
   ],
   "source": [
    "mae, mape, acc, preds, histories = run_model(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(histories[0].history['loss'], label='Training Loss')\n",
    "plt.plot(histories[0].history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FinBERT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
